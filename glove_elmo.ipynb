{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"glove_elmo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPCaFYAPvLrsAo3Dsrq6ViA"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q0CtFnu7h14U"},"source":["# This notebook contains implementation on classification using GloVe and ELMo embeddings\n","A few set up is required in using different embeddings, which will be described as follow"]},{"cell_type":"markdown","metadata":{"id":"AKyUuWFHwVN1"},"source":["Run the below blocks if you want to use GloVe embedding\n"]},{"cell_type":"code","metadata":{"id":"uisqdhnFVHRZ"},"source":["## Download and unzip glove pretrained embeddings\n","!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!apt-get -qq install unzip\n","!unzip glove.6B.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cy6eaSuSiNSM"},"source":["from gensim.models import word2vec\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","glove2word2vec(glove_input_file=\"glove.6B.300d.txt\", word2vec_output_file=\"gensim_glove_vectors.txt\")\n","from gensim.models.keyedvectors import KeyedVectors\n","glove_model = KeyedVectors.load_word2vec_format(\"gensim_glove_vectors.txt\", binary=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bgn260eNwiON"},"source":["Run the below blocks if you want to use ELMo embedding\n"]},{"cell_type":"code","metadata":{"id":"wOh4MdgSwZnw"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eLg3q7-kfggb"},"source":["# Here is for ELMo embedding\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras import backend as K\n","\n","sess = tf.Session()\n","K.set_session(sess)\n","elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n","with tf.Session() as sess:\n","  sess.run(tf.global_variables_initializer())\n","  sess.run(tf.tables_initializer())\n","  # x = sess.run(embeddings)\n","\n","# elmo_model = hub.load(\"https://tfhub.dev/google/elmo/2\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MRvp2Q5zwnKf"},"source":["#IMPORTANT\n","Note that you cannot switch from GloVe to ELMo embedding since ELMo does not support Tensorflow 2, you would need to reset the runtime in order to use ELMo if you previously were using GloVe\n","\n","While in terms of the speed in training, ELMo is much slower in training since it is using tensorflow 1\n","\n","I recommend it is more efficient to copy this notebook if you would like to train parallelly at the same time "]},{"cell_type":"code","metadata":{"id":"zlo2XL2pGXs1"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","mug_csv = pd.read_csv('mug.csv')\n","kettle_csv = pd.read_csv('kettle.csv')\n","bottle_csv = pd.read_csv('bottle.csv')\n","bakingtray_csv = pd.read_csv('bakingtray.csv')\n","hammer_csv = pd.read_csv('hammer.csv')\n","pan_csv = pd.read_csv('pan.csv')\n","wrench_csv = pd.read_csv('wrench.csv')\n","\n","\n","mug_csv['Object'] = ['mug'] * len(mug_csv)\n","kettle_csv['Object'] = ['kettle'] * len(kettle_csv)\n","bottle_csv['Object'] = ['bottle'] * len(bottle_csv)\n","bakingtray_csv['Object'] = ['bakingtray'] * len(bakingtray_csv)\n","hammer_csv['Object'] = ['hammer'] * len(hammer_csv)\n","pan_csv['Object'] = ['pan'] * len(pan_csv)\n","wrench_csv['Object'] = ['wrench'] * len(wrench_csv)\n","# mug_csv.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqeSXViKyzIV"},"source":["all_df = mug_csv.append(kettle_csv, ignore_index=True)\n","all_df = all_df.append(bottle_csv, ignore_index=True)\n","all_df = all_df.append(bakingtray_csv, ignore_index=True)\n","all_df = all_df.append(hammer_csv, ignore_index=True)\n","all_df = all_df.append(pan_csv, ignore_index=True)\n","all_df = all_df.append(wrench_csv, ignore_index=True)\n","\n","print(len(all_df))\n","all_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWSm84ShUloz"},"source":["import string # for preprocess_text()\n","import re\n","# NLTK library to remove the stopwords\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","'''\n","Want to try to method\n","1) change the digit to word\n","2) split the number into single digit\n","'''\n","num_to_word = {'1' : ' one ',\n","               '2' : ' two ',\n","               '3' : ' three ',\n","               '4' : ' four ',\n","               '5' : ' five ',\n","               '6' : ' six ',\n","               '7' : ' eight ',\n","               '8' : ' eight ',\n","               '9' : ' nine ',\n","               '0' : ' zero '}\n","\n","regex = '([0-9]+\\.?[0-9]+)([a-zA-Z]+)'\n","r = re.compile(regex)\n","\n","# unit conversion\n","convert_vol = {'oz'     : 29.5735,\n","               'cl'     : 10.0,\n","               'gallon' : 4546.09,\n","               'L'      : 1000.0}\n","char_set = \"abcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n","\n","class InputPreprocess():\n","  @staticmethod\n","  def quantize(val, to_values):\n","      \"\"\"Quantize a value with regards to a set of allowed values.\n","      \n","      Examples:\n","          quantize(49.513, [0, 45, 90]) -> 45\n","          quantize(43, [0, 10, 20, 30]) -> 30\n","      \n","      Note: function doesn't assume to_values to be sorted and\n","      iterates over all values (i.e. is rather slow).\n","      \n","      Args:\n","          val        The value to quantize\n","          to_values  The allowed values\n","      Returns:\n","          Closest value among allowed values.\n","      \"\"\"\n","      best_match = None\n","      best_match_diff = None\n","      for other_val in to_values:\n","          diff = abs(other_val - val)\n","          if best_match is None or diff <= best_match_diff:\n","              best_match = other_val\n","              best_match_diff = diff\n","      return best_match\n","\n","  # Preprocess weights --> e.g. 990g -> 990 <int>\n","  @staticmethod\n","  def preprocess_weights(df):\n","    tmp = df.copy()\n","    weights = tmp['Weight'].to_list()\n","    # Want to extract rows with 'g' only\n","    row_g = []\n","    for i in range(len(weights)):\n","      curr_weight = weights[i]\n","      if curr_weight.endswith('kg'):\n","        curr_weight = curr_weight[0:-2]\n","        curr_weight = float(curr_weight) * 1000\n","        # row_g.append(i)\n","      elif curr_weight.endswith('g'):\n","        curr_weight = curr_weight[0:-1]\n","        curr_weight = float(curr_weight)\n","        row_g.append(i)\n","      elif curr_weight.endswith('pounds'):\n","        curr_weight = curr_weight[0:-6]\n","        curr_weight = float(curr_weight) * 453.592\n","      elif curr_weight.endswith('oz'):\n","        curr_weight = curr_weight[0:-2]\n","        curr_weight = float(curr_weight) * 28.3495\n","      elif curr_weight == 'other':\n","        curr_weight = 0\n","      if curr_weight > 5000:\n","        curr_weight = 0\n","      weights[i] = int(curr_weight)\n","    tmp['Weight'] = weights\n","    return tmp, row_g\n","  \n","  @staticmethod\n","  def preprocess_volume(df):\n","    tmp = df.copy()\n","    volume = tmp['Volume'].to_list()\n","    for i in range(len(volume)):\n","      curr_volume = volume[i].split(';')[0] # now only consider to first element in the labels\n","\n","      if curr_volume.endswith('ml'):\n","        curr_volume = float(curr_volume[0:-2])\n","      elif curr_volume.endswith('oz'):\n","        curr_volume = float(curr_volume[0:-2]) * convert_vol['oz']\n","      elif curr_volume.endswith('g'):\n","        curr_volume = float(curr_volume[0:-1])\n","      elif curr_volume.endswith('cl'):\n","        curr_volume = float(curr_volume[0:-2]) * convert_vol['cl']\n","      elif curr_volume.endswith('L'):\n","        curr_volume = float(curr_volume[0:-1]) * convert_vol['L']\n","      elif curr_volume.endswith('gallon'):\n","        curr_volume = float(curr_volume[0:-6]) * convert_vol['gallon']\n","      elif curr_volume == 'other':\n","        curr_volume = 0\n","      volume[i] = int(curr_volume)\n","      # if volume[i] > 5000:\n","      #   volume[i] = 0\n","    tmp['Volume'] = volume\n","    return tmp\n","\n","  @staticmethod\n","  def convert_num2words(word_list):\n","    tmp_word_list = []\n","    for word in word_list:\n","      if word[0].isdigit() and word[-1].isdigit():\n","        try:\n","          num_in_word = num2words(float(word))\n","          tmp_word_list.append(num_in_word)\n","        except ValueError as e:\n","          tmp_word_list.append(word)\n","      else:\n","        tmp_word_list.append(word)\n","    return tmp_word_list\n","  @staticmethod\n","  def separate_num_unit(word_list):\n","    tmp_word_list = []\n","    for word in word_list:\n","      if word == '':\n","        continue\n","      m = r.match(word)\n","      if m is not None:\n","        tmp_word_list.extend(list(m.groups()))\n","      else:\n","        tmp_word_list.append(word)\n","    return tmp_word_list\n","\n","  @staticmethod\n","  def remove_stopwords(text):\n","    words = [w for w in text if w not in stopwords.words('english')]\n","    return words\n","  \n","  @staticmethod\n","  def remove_out_of_char(sentence):\n","    res = ''\n","    for ch in sentence:\n","      if ch in char_set:\n","        res += ch\n","      else:\n","        res += ' '\n","    return res\n","  \"\"\"\n","  Clean the text with the following rules\n","  - Convert newline \\n to white space\n","  - Convert tab \\t to white space\n","  - Lowercase all texts\n","  - Covert punctuation to white space\n","\n","  \"\"\"\n","  @staticmethod\n","  def preprocess_text(df, column):\n","    tmp = df.copy()\n","    for i in range(len(tmp)):\n","      s = tmp[column][i]\n","      s = s.lower()\n","      s = s.replace('\\n', ' ') \n","      s = s.replace('\\t', ' ')\n","      s = InputPreprocess.remove_out_of_char(s)\n","      word_list = s.split(' ')\n","      # handle cases like 12oz -> 12 oz (separate the value and the unit)\n","      tmp_word_list = InputPreprocess.separate_num_unit(word_list)\n","\n","      # word_list = InputPreprocess.convert_num2words(tmp_word_list)\n","      s = ' '.join(tmp_word_list)\n","      res_string = ''\n","      for j in range(len(s)):\n","        if s[j] == '.' and j-1 > 0 and j+1 < len(s) and s[j-1].isdigit() and s[j+1].isdigit():\n","          res_string += s[j]\n","        elif s[j] in string.punctuation:\n","          continue\n","        else:\n","          res_string += s[j]\n","\n","      # s = \" \".join(\"\".join([\" \" if ch in string.punctuation else ch for ch in s]).split())\n","      tmp.at[i, column] = res_string.split(' ')\n","    return tmp\n","  \n","  @staticmethod\n","  def preprocess_dimensions(df):\n","    tmp = df.copy()\n","    length, width, height = tmp['Length'], tmp['Width'], tmp['Height']\n","    res_length, res_width, res_height = [], [], []\n","    for i in range(len(df)):\n","      if length[i] == 'other':\n","        res_length.append(0)\n","      else:\n","        res_length.append(int(round(float(length[i]))))\n","\n","      if width[i] == 'other':\n","        res_width.append(0)\n","      else:\n","        res_width.append(int(round(float(width[i]))))\n","\n","      if height[i] == 'other':\n","        res_height.append(0)\n","      else:\n","        res_height.append(int(round(float(height[i]))))\n","    tmp['Length'], tmp['Width'], tmp['Height'] = res_length, res_width, res_height\n","    return tmp\n","\n","  @staticmethod\n","  def parts_into_list(df):\n","    tmp = df.copy()\n","    for i in range(len(tmp)):\n","      s = tmp['Parts'][i]\n","      s = s.split(';')\n","      tmp.at[i, 'Parts'] = s\n","    return tmp    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9InHmRaSo_p"},"source":["# Pre-process on input text\n","obj_df = InputPreprocess.preprocess_text(all_df, 'Input')\n","obj_df = InputPreprocess.preprocess_text(obj_df, 'UnstructuredText')\n","obj_df = InputPreprocess.preprocess_text(obj_df, 'StructuredText')\n","obj_df['Input'] = obj_df['Input'].apply(lambda x: InputPreprocess.remove_stopwords(x))\n","obj_df['UnstructuredText'] = obj_df['UnstructuredText'].apply(lambda x: InputPreprocess.remove_stopwords(x))\n","obj_df['StructuredText'] = obj_df['StructuredText'].apply(lambda x: InputPreprocess.remove_stopwords(x))\n","\n","\n","# Pre-process on weight and volume\n","\n","obj_df, row_g = InputPreprocess.preprocess_weights(obj_df)\n","obj_df = InputPreprocess.preprocess_volume(obj_df)\n","\n","weight_bins = np.arange(min(obj_df['Weight']), max(obj_df['Weight']), 10)\n","volume_bins = np.arange(min(obj_df['Volume']), max(obj_df['Volume']), 10)\n","\n","\n","obj_df['Weight'] = obj_df['Weight'].apply(lambda x : InputPreprocess.quantize(x, weight_bins))\n","obj_df['Volume'] = obj_df['Volume'].apply(lambda x : InputPreprocess.quantize(x, volume_bins))\n","\n","# Pre-process on dimensions\n","obj_df = InputPreprocess.preprocess_dimensions(obj_df)\n","length_bins = np.arange(min(obj_df['Length']), max(obj_df['Length']), 1)\n","width_bins = np.arange(min(obj_df['Width']), max(obj_df['Width']), 1)\n","height_bins = np.arange(min(obj_df['Height']), max(obj_df['Height']), 1)\n","obj_df['Length'] = obj_df['Length'].apply(lambda x : InputPreprocess.quantize(x, length_bins))\n","obj_df['Width'] = obj_df['Width'].apply(lambda x : InputPreprocess.quantize(x, width_bins))\n","obj_df['Height'] = obj_df['Height'].apply(lambda x : InputPreprocess.quantize(x, height_bins))\n","\n","# Pre-process on object parts\n","obj_df = InputPreprocess.parts_into_list(obj_df)\n","obj_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxPVznHgJAOs"},"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","mlb = MultiLabelBinarizer()\n","obj_df['Parts'] = list(mlb.fit_transform(list(obj_df['Parts'])))\n","obj_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ie9NcSLLXIuU"},"source":["'''\n","Show distribution on weight and volume\n","'''\n","plt.style.use('ggplot')\n","fig = plt.figure(figsize=(10, 3), dpi=200)\n","ax1 = fig.add_subplot(1, 3, 1)\n","ax2 = fig.add_subplot(1, 3, 2)\n","ax3 = fig.add_subplot(1, 3, 3)\n","\n","ax1.hist(pd.to_numeric(obj_df['Length']), bins = 70)\n","ax2.hist(pd.to_numeric(obj_df['Width']), bins = 70)\n","ax3.hist(pd.to_numeric(obj_df['Height']), bins = 70)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dGrEDK3j9t6M"},"source":["print('Number of bins for quantize: {}.  Number of actual bins after quantise: {}'.format(len(weight_bins), len(set(obj_df['Weight']))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fsc7axVrpRl"},"source":["'''\n","Show distribution on weight and volume\n","'''\n","fig = plt.figure(figsize=(7, 3), dpi=200)\n","ax1 = fig.add_subplot(1, 2, 1)\n","ax2 = fig.add_subplot(1, 2, 2)\n","\n","ax1.hist(obj_df['Weight'], bins = 50)\n","ax2.hist(obj_df['Volume'], bins = 50)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwV7J2pxoFS5"},"source":["'''\n","Run this if we only want gram only\n","''' \n","# gram_only_df = obj_df.copy().iloc[row_g].reset_index(drop=True)\n","# gram_only_df.head()\n","# obj_df = gram_only_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mwc78wrFJDjm"},"source":["material_list = list(set(obj_df[\"Material\"]))\n","print(len(material_list), material_list)\n","\n","colour_list = list(set(obj_df['Colour']))\n","print(len(colour_list), colour_list)\n","\n","weight_list = list(set(obj_df['Weight']))\n","print(len(weight_list), sorted(weight_list))\n","\n","volume_list = list(set(obj_df['Volume']))\n","print(len(volume_list), sorted(volume_list))\n","\n","object_list = list(set(obj_df['Object']))\n","print(len(object_list), sorted(object_list))\n","\n","length_list = list(set(obj_df['Length']))\n","print(len(length_list), sorted(length_list))\n","\n","width_list = list(set(obj_df['Width']))\n","print(len(width_list), sorted(width_list))\n","\n","height_list = list(set(obj_df['Height']))\n","print(len(height_list), sorted(height_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kFfWixiqS0Vu"},"source":["# Look at the maximum input length\n","lennn = []\n","for i in range(len(obj_df)):\n","  lennn.append(len(obj_df.iloc[i, 0]))\n","print(min(lennn), max(lennn))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKnYqcGrZIjK"},"source":["'''\n","Plot input text length\n","'''\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","%matplotlib inline\n","fig = plt.figure(figsize=(15, 4), dpi=200)\n","ax1 = fig.add_subplot(1, 3, 1)\n","ax2 = fig.add_subplot(1, 3, 2)\n","ax3 = fig.add_subplot(1, 3, 3)\n","ax1.hist([len(sen) for sen in obj_df[\"Input\"]], bins=50)\n","ax2.hist([len(sen) for sen in obj_df[\"UnstructuredText\"]], bins=50)\n","ax3.hist([len(sen) for sen in obj_df[\"StructuredText\"]], bins=50)\n","\n","ax1.tick_params(axis='both', which='major', labelsize=12)\n","ax1.tick_params(axis='both', which='minor', labelsize=12)\n","ax1.set_xlabel('Length of sentence', fontsize=14)\n","ax1.set_ylabel('Number of sentences', fontsize=14)\n","ax1.set_title('All Text')\n","\n","ax2.tick_params(axis='both', which='major', labelsize=12)\n","ax2.tick_params(axis='both', which='minor', labelsize=12)\n","ax2.set_xlabel('Length of sentence', fontsize=14)\n","ax2.set_ylabel('Number of sentences', fontsize=14)\n","ax2.set_title('Unstructured Text')\n","\n","ax3.tick_params(axis='both', which='major', labelsize=12)\n","ax3.tick_params(axis='both', which='minor', labelsize=12)\n","ax3.set_xlabel('Length of sentence', fontsize=14)\n","ax3.set_ylabel('Number of sentences', fontsize=14)\n","ax3.set_title('Structured Text')\n","\n","# plt.savefig('text_length_distribution.png')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ovVtHjcr_28"},"source":["# Create the dictionary for material and colour\n","material_to_idx = {x : i for i, x in enumerate(material_list)}\n","colour_to_idx = {x : i for i, x in enumerate(colour_list)}\n","weight_to_idx = {x : i for i, x in enumerate(weight_list)}\n","volume_to_idx = {x : i for i, x in enumerate(volume_list)}\n","object_to_idx = {x : i for i, x in enumerate(object_list)}\n","length_to_idx = {x : i for i, x in enumerate(length_list)}\n","width_to_idx = {x : i for i, x in enumerate(width_list)}\n","height_to_idx = {x : i for i, x in enumerate(height_list)}\n","# Now update the label to integer form\n","for i in range(len(obj_df)):\n","  obj_df.iloc[i, 3] = material_to_idx[obj_df.iloc[i, 3]]\n","  obj_df.iloc[i, 4] = colour_to_idx[obj_df.iloc[i, 4]]\n","  obj_df.iloc[i, 5] = weight_to_idx[obj_df.iloc[i, 5]]\n","  obj_df.iloc[i, 6] = volume_to_idx[obj_df.iloc[i, 6]]\n","  obj_df.iloc[i, 7] = length_to_idx[obj_df.iloc[i, 7]]\n","  obj_df.iloc[i, 8] = width_to_idx[obj_df.iloc[i, 8]]\n","  obj_df.iloc[i, 9] = height_to_idx[obj_df.iloc[i, 9]]\n","  obj_df.iloc[i, -1] = object_to_idx[obj_df.iloc[i, -1]]\n","obj_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"St2cXc4c4rm0"},"source":["# Generate the set of word and get input sequence\n","def get_wordset(df, text_type):\n","  word_set = set()\n","  sequence_len = []\n","  for i in range(len(df)):\n","    list_of_word = df[text_type][i]\n","    word_set.update(list_of_word)\n","    sequence_len.append(len(list_of_word))\n","  print(\"Number of words in {}: {}  and maximum sequence length: {}\".format(text_type, len(word_set), max(sequence_len)))\n","  return word_set, sequence_len\n","\n","word_set, sequence_len = get_wordset(obj_df, 'Input')\n","unstruct_word_set, unstruct_sequence_len = get_wordset(obj_df, 'UnstructuredText')\n","struct_word_set, struct_sequence_len = get_wordset(obj_df, 'StructuredText')\n","\n","input_sequences = list(obj_df['Input'])\n","unstruct_input_sequences = list(obj_df['UnstructuredText'])\n","struct_input_sequences = list(obj_df['StructuredText'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rXLw3N5dSmf"},"source":["\"\"\"\n","Convert the material labels column to categorical\n","Pad sequence\n","Find number of unique tokens (words)\n","\"\"\"\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","# from keras.utils import to_categorical\n","\n","\n","def tok_and_pad_seq(word_set, sequence_len, input_sequences):\n","  MAX_NUM_WORDS = len(word_set)\n","  MAX_SEQUENCE_LENGTH = max(sequence_len)\n","  tokenizer = tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n","  tokenizer.fit_on_texts(input_sequences)\n","  sequences = tokenizer.texts_to_sequences(input_sequences)\n","  word_index = tokenizer.word_index\n","  print(f'Found {len(word_index)} unique tokens.')\n","  padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n","  return MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH, word_index, padded_sequences, tokenizer\n","\n","######################################################\n","# For unstructured + structured input\n","MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH, word_index, padded_sequences, tokenizer = tok_and_pad_seq(word_set, sequence_len, input_sequences)\n","\n","######################################################\n","# For unstructured input\n","unstruct_preproc = tok_and_pad_seq(unstruct_word_set, unstruct_sequence_len, unstruct_input_sequences)\n","UNSTRUCT_MAX_NUM_WORDS, UNSTRUCT_MAX_SEQUENCE_LENGTH, unstruct_word_index, unstruct_padded_sequences, unstruct_tokenizer = unstruct_preproc\n","\n","# For structured input\n","struct_preproc = tok_and_pad_seq(struct_word_set, struct_sequence_len, struct_input_sequences)\n","STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH, struct_word_index, struct_padded_sequences, struct_tokenizer = struct_preproc\n","######################################################\n","\n","\n","material_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Material']))\n","colour_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Colour']))\n","weight_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Weight']))\n","volume_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Volume']))\n","object_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Object']))\n","length_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Length']))\n","width_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Width']))\n","height_labels = tf.keras.utils.to_categorical(np.asarray(obj_df['Height']))\n","\n","print(padded_sequences.shape,\n","      material_labels.shape,\n","      colour_labels.shape,\n","      weight_labels.shape,\n","      volume_labels.shape,\n","      object_labels.shape,\n","      length_labels.shape,\n","      width_labels.shape,\n","      height_labels.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AKoSpiB9W63"},"source":["'''\n","Run this block only if using ELMo embedding\n","'''\n","\n","batch_size = 32\n","def ElmoEmbedding(x):\n","  return elmo_model(inputs={\"tokens\": tf.squeeze(tf.cast(x, tf.string)),\"sequence_len\": tf.constant(batch_size*[MAX_SEQUENCE_LENGTH])\n","                     },\n","                      signature=\"tokens\",\n","                      as_dict=True)[\"elmo\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6fLSLYl1dWaU"},"source":["'''\n","Runn this block only if using GloVe embedding\n","'''\n","# now prepare the embedding matrix\n","import tensorflow as tf\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, Dropout, Flatten, Add, Lambda\n","from keras.layers import LSTM\n","from keras.utils import np_utils\n","\n","def get_embedding_matrix(MAX_NUM_WORDS, word_index):\n","  embedding_matrix = np.zeros((MAX_NUM_WORDS + 1, 300)) # 300 as we're using glove.6B.300d\n","  for word, i in word_index.items():\n","    if i > MAX_NUM_WORDS:\n","      continue\n","    if word in glove_model:\n","      embedding_vector = glove_model[word]\n","      if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros\n","        embedding_matrix[i] = embedding_vector\n","  return embedding_matrix\n","embedding_matrix = get_embedding_matrix(MAX_NUM_WORDS, word_index)\n","unstruct_embedding_matrix = get_embedding_matrix(UNSTRUCT_MAX_NUM_WORDS, unstruct_word_index)\n","struct_embedding_matrix = get_embedding_matrix(STRUCT_MAX_NUM_WORDS, struct_word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6QiB7eyozcD"},"source":["import tensorflow as tf\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Embedding, Dropout, Flatten, Add, Lambda\n","from keras.layers import LSTM\n","from keras.utils import np_utils\n","from keras.layers.wrappers import Bidirectional\n","from keras.layers import GlobalMaxPool1D, concatenate\n","from keras.layers import LSTM\n","from keras.models import Model\n","from keras.layers import Input\n","from keras.layers import BatchNormalization\n","from keras.layers.merge import add\n","\n","\n","class ObjectPropertiesExtractionModel():\n","  \"\"\"\n","    We will have different branch that represents the prediction of \n","    different properties of the object\n","  \"\"\"\n","\n","  def __init__(self,\n","               material_labels,\n","               colour_labels,\n","               weight_labels,\n","               volume_labels,\n","               object_labels,\n","               length_labels, width_labels, height_labels, nb_parts, prop):\n","    self.nb_material_classes = material_labels\n","    self.nb_colour_classes = colour_labels\n","    self.nb_weight_classes = weight_labels\n","    self.nb_volume_classes = volume_labels\n","    self.nb_object_classes = object_labels\n","    self.nb_length_classes = length_labels\n","    self.nb_width_classes = width_labels\n","    self.nb_height_classes = height_labels\n","    self.nb_parts = nb_parts\n","    self.prop = prop\n","\n","  def make_default_hidden_layers_elmo(self, inputs, MAX_SEQUENCE_LENGTH):\n","    embedding = Lambda(ElmoEmbedding, output_shape=(MAX_SEQUENCE_LENGTH, 1024))(inputs)\n","    x = Bidirectional(LSTM(units=256))(embedding)\n","    return x\n","\n","  def make_default_hidden_layers(self, inputs, embedding_matrix, embedding_dim, MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH):\n","    embedding = Embedding(MAX_NUM_WORDS + 1,\n","                    embedding_dim,\n","                    input_length=MAX_SEQUENCE_LENGTH,\n","                    weights=[embedding_matrix],\n","                            trainable=True)(inputs) #Configure the trainable param\n","    x = Bidirectional(LSTM(256))(embedding)\n","    return x\n","\n","  def make_material_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_material_classes, activation='softmax', name='material_output')(x)\n","    return x\n","\n","  def make_colour_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_colour_classes, activation='softmax', name='colour_output')(x)\n","    return x\n","\n","  def make_weight_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_weight_classes, activation='softmax', name='weight_output')(x)\n","    return x\n","\n","  def make_volume_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_volume_classes, activation='softmax', name='volume_output')(x)\n","    return x\n","  \n","  def make_object_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_object_classes, activation='softmax', name='object_output')(x)\n","    return x\n","\n","  def make_length_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_length_classes, activation='softmax', name='length_output')(x)\n","    return x\n","\n","  def make_width_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_width_classes, activation='softmax', name='width_output')(x)\n","    return x\n","\n","  def make_height_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_height_classes, activation='softmax', name='height_output')(x)\n","    return x\n","\n","  def make_obj_parts_branch(self, input):\n","    x = BatchNormalization()(input)\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    x = Dense(self.nb_parts, activation='sigmoid', name='parts_output')(x)\n","    return x\n","\n","  def assemble_full_model_multi_input(self, unstruct_embedding_matrix, struct_embedding_matrix, embedding_dim,\n","                                      STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH,\n","                                      UNSTRUCT_MAX_NUM_WORDS, UNSTRUCT_MAX_SEQUENCE_LENGTH):\n","    struct_input = Input(shape=(STRUCT_MAX_SEQUENCE_LENGTH, ))\n","    unstruct_input = Input(shape=(UNSTRUCT_MAX_SEQUENCE_LENGTH, ))\n","\n","    struct_hidden = self.make_default_hidden_layers(struct_input, struct_embedding_matrix, embedding_dim, STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH)\n","    unstruct_hidden = self.make_default_hidden_layers(unstruct_input, unstruct_embedding_matrix, embedding_dim, UNSTRUCT_MAX_NUM_WORDS, UNSTRUCT_MAX_SEQUENCE_LENGTH)\n","\n","    combined = concatenate([struct_hidden, unstruct_hidden])\n","    material_branch = self.make_material_branch(combined)\n","    colour_branch = self.make_colour_branch(combined)\n","    weight_branch = self.make_weight_branch(combined)\n","    volume_branch = self.make_volume_branch(combined)\n","    object_branch = self.make_object_branch(combined)\n","    length_branch = self.make_length_branch(combined)\n","    width_branch = self.make_width_branch(combined)\n","    height_branch = self.make_height_branch(combined)\n","\n","    model = Model(inputs=[unstruct_input, struct_input], outputs=[material_branch,\n","                                                                  colour_branch,\n","                                                                  weight_branch,\n","                                                                  volume_branch,\n","                                                                  object_branch,\n","                                                                  length_branch,\n","                                                                  width_branch,\n","                                                                  height_branch])\n","    return model\n","\n","  def assemble_full_model(self, embedding_matrix, embedding_dim, MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH, embed):\n","    input_shape = (MAX_SEQUENCE_LENGTH,)\n","    if embed == 'glove':\n","      inputs = Input(shape=input_shape)\n","      x = self.make_default_hidden_layers(inputs, embedding_matrix, embedding_dim, MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH)\n","    elif embed == 'elmo':\n","      inputs = Input(shape=input_shape, dtype=tf.string)\n","      x = self.make_default_hidden_layers_elmo(inputs, MAX_SEQUENCE_LENGTH)\n","\n","\n","    material_branch = self.make_material_branch(x)\n","    colour_branch = self.make_colour_branch(x)\n","    weight_branch = self.make_weight_branch(x)\n","    volume_branch = self.make_volume_branch(x)\n","    object_branch = self.make_object_branch(x)\n","    length_branch = self.make_length_branch(x)\n","    width_branch = self.make_width_branch(x)\n","    height_branch = self.make_height_branch(x)\n","    parts_branch = self.make_obj_parts_branch(x)\n","\n","    '''\n","    Return single output\n","    '''\n","    # model = Model(inputs=inputs, outputs=parts_branch)\n","    '''\n","    Return multiple output\n","    '''\n","    model = Model(inputs=inputs, outputs=[material_branch,\n","                                          colour_branch,\n","                                          weight_branch,\n","                                          volume_branch,\n","                                          object_branch,\n","                                          length_branch,\n","                                          width_branch,\n","                                          height_branch,\n","                                          parts_branch])\n","    # if self.prop == 'material':\n","    #   model = Model(inputs=inputs, outputs=material_branch)\n","    # if self.prop == 'colour':\n","    #   model = Model(inputs=inputs, outputs=colour_branch)\n","    # elif self.prop == 'weight':\n","    #   model = Model(inputs=inputs, outputs=weight_branch)\n","    # elif self.prop == 'volume':\n","    #   model = Model(inputs=inputs, outputs=volume_branch)\n","    # elif self.prop == 'object':\n","    #   model = Model(inputs=inputs, outputs=object_branch)\n","    # elif self.prop == 'length':\n","    #   model = Model(inputs=inputs, outputs=length_branch)\n","    # elif self.prop == 'width':\n","    #   model = Model(inputs=inputs, outputs=width_branch)\n","    # elif self.prop == 'height':\n","    #   model = Model(inputs=inputs, outputs=height_branch)\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91IRQVoSA6CY"},"source":["'''\n","Change the embedding to glove/elmo\n","'''\n","embedding_dim = 300\n","embed = 'glove'\n","\n","def get_single_output_model_elmo(embed):\n","  prop_list = ['material', 'colour', 'weight', 'volume', 'object', 'length', 'width', 'height']\n","  models = []\n","  for i in prop_list:\n","    helper = ObjectPropertiesExtractionModel(len(material_list),\n","                                            len(colour_list),\n","                                            len(weight_list),\n","                                            len(volume_list),\n","                                            len(object_list),\n","                                            len(length_list),\n","                                            len(width_list),\n","                                            len(height_list), i)\n","    if embed == 'elmo':\n","      model = helper.assemble_full_model(None, None, None, MAX_SEQUENCE_LENGTH) #for ELMo\n","    elif embed == 'glove':\n","      model = helper.assemble_full_model(struct_embedding_matrix, embedding_dim, STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH)\n","    models.append(model)\n","  return models\n","\n","helper = ObjectPropertiesExtractionModel(len(material_list),\n","                                         len(colour_list),\n","                                         len(weight_list),\n","                                         len(volume_list),\n","                                         len(object_list),\n","                                         len(length_list),\n","                                         len(width_list),\n","                                         len(height_list), len(list(mlb.classes_)), None)\n","\n","# model = helper.assemble_full_model(None, None, None, MAX_SEQUENCE_LENGTH, 'elmo') #for ELMo\n","'''\n","For GloVe using all of the text\n","to use structured text only, for example\n","model = helper.assemble_full_model(struct_embedding_matrix, embedding_dim, STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH, 'glove')\n","'''\n","model = helper.assemble_full_model(embedding_matrix, embedding_dim, MAX_NUM_WORDS, MAX_SEQUENCE_LENGTH, 'glove')\n","# model = helper.assemble_full_model_multi_input(unstruct_embedding_matrix, struct_embedding_matrix, embedding_dim,\n","#                                                STRUCT_MAX_NUM_WORDS, STRUCT_MAX_SEQUENCE_LENGTH,\n","#                                                UNSTRUCT_MAX_NUM_WORDS, UNSTRUCT_MAX_SEQUENCE_LENGTH, 'glove') # for GloVe with multiple input\n","\n","# ELMo - single output\n","# models = get_single_output_model_elmo()\n","# material_model, colour_model, weight_model, volume_model, object_model, length_model, width_model, height_model = models[0], models[1], models[2], models[3], models[4], models[5], models[6], models[7]\n","\n","# material_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# colour_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# weight_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# volume_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# object_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# length_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# width_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","# height_model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","\n","\n","# For multiple output\n","losses = {\n","    \"material_output\": \"categorical_crossentropy\",\n","    \"colour_output\": \"categorical_crossentropy\",\n","    \"weight_output\": \"categorical_crossentropy\",\n","    \"volume_output\": \"categorical_crossentropy\",\n","    \"object_output\": \"categorical_crossentropy\",\n","    \"length_output\": \"categorical_crossentropy\",\n","    \"width_output\": \"categorical_crossentropy\",\n","    \"height_output\": \"categorical_crossentropy\",\n","    'parts_output' : 'binary_crossentropy'\n","}\n","\n","model.compile(loss=losses, optimizer='adam', metrics=['accuracy'])\n","\n","# model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","\n","'''To predict object parts only'''\n","# model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n","\n","\n","model.summary()\n","# plot_model(model, to_file=\"MultipleOutputModel.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay9I_9tM38gD"},"source":["'''\n","Plot the model\n","'''\n","tf.keras.utils.plot_model(model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nj66thwBxmLP"},"source":["'''\n","ELMo embedding only\n","'''\n","# Now get the data for elmo embedding\n","\n","input_list = obj_df['Input'].tolist()\n","\n","# Pre-pad\n","new_input_list = []\n","\n","for seq in input_list:\n","  new_seq = []\n","  for i in range(MAX_SEQUENCE_LENGTH - len(seq)):\n","    new_seq.append(\"PADword\")\n","  for w in seq:\n","    new_seq.append(w)\n","  new_input_list.append(new_seq)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_EGF_KK2dzo"},"source":["'''\n","ELMo embedding only\n","'''\n","from sklearn.model_selection import train_test_split\n","split_data = train_test_split(np.asarray(new_input_list),\n","                              material_labels,\n","                              colour_labels,\n","                              weight_labels,\n","                              volume_labels,\n","                              object_labels,\n","                              length_labels,\n","                              width_labels,\n","                              height_labels,\n","                              np.asarray(list(obj_df['Parts'])),\n","                              test_size=0.20, random_state=33)\n","(x_train, x_test,\n"," y_train_material, y_test_material,\n"," y_train_colour, y_test_colour,\n"," y_train_weight, y_test_weight,\n"," y_train_volume, y_test_volume,\n"," y_train_object, y_test_object,\n"," y_train_length, y_test_length,\n"," y_train_width, y_test_width,\n"," y_train_height, y_test_height,\n"," y_train_parts, y_test_parts) = split_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TDWX4B4bUF03"},"source":["'''\n","GloVe embedding only\n","'''\n","\n","from sklearn.model_selection import train_test_split\n","split_data = train_test_split(padded_sequences,\n","                              unstruct_padded_sequences,\n","                              struct_padded_sequences,\n","                              material_labels,\n","                              colour_labels,\n","                              weight_labels,\n","                              volume_labels,\n","                              object_labels,\n","                              length_labels,\n","                              width_labels,\n","                              height_labels,\n","                              np.asarray(list(obj_df['Parts'])),\n","                              test_size=0.20, random_state=33)\n","\n","(x_train, x_test,\n"," unstruct_x_train, unstruct_x_test,\n"," struct_x_train, struct_x_test,\n"," y_train_material, y_test_material,\n"," y_train_colour, y_test_colour,\n"," y_train_weight, y_test_weight,\n"," y_train_volume, y_test_volume,\n"," y_train_object, y_test_object,\n"," y_train_length, y_test_length,\n"," y_train_width, y_test_width,\n"," y_train_height, y_test_height,\n"," y_train_parts, y_test_parts) = split_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kDOD14oAOx_t"},"source":["# For multiple input - GloVe\n","\n","EPOCHS = 50\n","# history = model.fit(x=[unstruct_x_train, struct_x_train], y=y_train_weight, epochs=EPOCHS, validation_data=([unstruct_x_test, struct_x_test], y_test_weight), verbose=2)\n","history = model.fit(x=[unstruct_x_train, struct_x_train],\n","                    y={\"material_output\": y_train_material,\n","                       \"colour_output\": y_train_colour,\n","                       'weight_output': y_train_weight,\n","                       'volume_output' : y_train_volume,\n","                       'object_output' : y_train_object,\n","                       'length_output' : y_train_length,\n","                       'width_output' : y_train_width,\n","                       'height_output' : y_train_height},\n","                    batch_size=32,\n","                    validation_data=([unstruct_x_test, struct_x_test],\n","                                     {\"material_output\": y_test_material,\n","                                      \"colour_output\": y_test_colour,\n","                                      'weight_output': y_test_weight,\n","                                      'volume_output' : y_test_volume,\n","                                      'object_output' : y_test_object,\n","                                      'length_output' : y_test_length,\n","                                      'width_output' : y_test_width,\n","                                      'height_output' : y_test_height}),\n","                    epochs=EPOCHS,\n","                    verbose=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPzdO3Xv9SF9"},"source":["# Set up directory to save best model\n","# NOTE: TF1 does not support saving best model\n","!rm -rf best_model\n","!mkdir best_model\n","path = './best_model'\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(path, monitor='loss', save_best_only=True, verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-i-JCtyiRTY"},"source":["'''\n","NOTE: for training ELMo embedding\n","It is found that there will be error if the size of the validation is not dividable (maybe TF1 issues?)\n","for example if I have 200 test samples, with batch size of 32\n","I can only train it without error by using 192 test samples (192 % 32 = 0)\n","Similar technique should also be applied for x_train as well\n","'''\n","\n","from sklearn.model_selection import train_test_split\n","path = './best_model'\n","\n","EPOCHS = 50\n","\n","# ######################### For ELMo embedding\n","'''\n","Single output\n","'''\n","# history = model.fit(x_train, y_train_parts,\n","#                     epochs=50, batch_size=batch_size,\n","#                     validation_data=(x_test[0:batch_size*9], y_test_parts[0:batch_size*9]), verbose=1)\n","\n","'''\n","Multiple output\n","'''\n","# history = model.fit(x_train,\n","#                     y={\"material_output\": y_train_material,\n","#                        \"colour_output\": y_train_colour,\n","#                        'weight_output': y_train_weight,\n","#                        'volume_output': y_train_volume,\n","#                        'object_output': y_train_object,\n","#                        'length_output': y_train_length,\n","#                        'width_output': y_train_width,\n","#                        'height_output': y_train_height,\n","#                        'parts_output': y_train_parts},\n","#                     validation_data=(x_test[0:batch_size*9],\n","#                                      {\"material_output\": y_test_material[0:batch_size*9],\n","#                                       \"colour_output\": y_test_colour[0:batch_size*9],\n","#                                       'weight_output': y_test_weight[0:batch_size*9],\n","#                                       'volume_output': y_test_volume[0:batch_size*9],\n","#                                       'object_output': y_test_object[0:batch_size*9],\n","#                                       'length_output': y_test_length[0:batch_size*9],\n","#                                       'width_output': y_test_width[0:batch_size*9],\n","#                                       'height_output': y_test_height[0:batch_size*9],\n","#                                       'parts_output': y_test_parts[0:batch_size*9]}),\n","#                     epochs=EPOCHS,\n","#                     batch_size=batch_size,\n","#                     verbose=1)\n","\n","\n","# ######################### For Glove embedding\n","'''\n","Single output\n","'''\n","# history = model.fit(x_train, y_train_parts, epochs=100, validation_data=(x_test, y_test_parts), verbose=2)\n","\n","'''\n","Multiple output\n","'''\n","history = model.fit(x=x_train,\n","                    y={\"material_output\": y_train_material,\n","                       \"colour_output\": y_train_colour,\n","                       'weight_output': y_train_weight,\n","                       'volume_output' : y_train_volume,\n","                       'object_output' : y_train_object,\n","                       'length_output' : y_train_length,\n","                       'width_output' : y_train_width,\n","                       'height_output' : y_train_height,\n","                       'parts_output' : y_train_parts},\n","                    batch_size=32,\n","                    validation_data=(x_test,\n","                                     {\"material_output\": y_test_material,\n","                                      \"colour_output\": y_test_colour,\n","                                      'weight_output': y_test_weight,\n","                                      'volume_output' : y_test_volume,\n","                                      'object_output' : y_test_object,\n","                                      'length_output' : y_test_length,\n","                                      'width_output' : y_test_width,\n","                                      'height_output' : y_test_height,\n","                                      'parts_output' : y_test_parts}),\n","                    epochs=200,\n","                    # callbacks=[checkpoint],\n","                    verbose=1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tT3rzHrM_B83"},"source":["# Look at classification report\n","from sklearn.metrics import classification_report\n","pred = model.predict(x_test)\n","report = classification_report(np.argmax(y_test_volume, axis=1), np.argmax(pred[3], axis=1))\n","print(report)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m21H6X-222Jq"},"source":["# The below blocks are pipeline for training single output w.r.t different embedding"]},{"cell_type":"code","metadata":{"id":"bkvaNIEo9kJn"},"source":["colour_history = colour_model.fit(x_train, y_train_colour,\n","                    epochs=EPOCHS, batch_size=batch_size,\n","                    validation_data=(x_test[0:batch_size*9], y_test_colour[0:batch_size*9]), verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pg2mdKEOpOm_"},"source":["# weight_history = weight_model.fit(x_train, y_train_weight,\n","#                     epochs=5, batch_size=batch_size,\n","#                     validation_data=(x_test[0:batch_size*9], y_test_weight[0:batch_size*9]), verbose=1)\n","weight_history = weight_model.fit(struct_x_train, y_train_weight, epochs=40, validation_data=(struct_x_test, y_test_weight), callbacks=[checkpoint], verbose=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9zArX-xwI_c"},"source":["weight_model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2oju09ypN1D"},"source":["# volume_history = volume_model.fit(x_train, y_train_volume,\n","#                     epochs=1, batch_size=batch_size,\n","#                     validation_data=(x_test[0:batch_size*9], y_test_volume[0:batch_size*9]), verbose=1)\n","volume_history = volume_model.fit(struct_x_train, y_train_volume, epochs=40, validation_data=(struct_x_test, y_test_volume), callbacks=[checkpoint], verbose=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pGV-bsgPx0BQ"},"source":["volume_model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6W4ePYBDpcsK"},"source":["object_history = object_model.fit(x_train, y_train_object,\n","                    epochs=EPOCHS, batch_size=batch_size,\n","                    validation_data=(x_test[0:batch_size*9], y_test_object[0:batch_size*9]), verbose=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a_H2unbRpibI"},"source":["# length_history = length_model.fit(x_train, y_train_length,\n","#                     epochs=1, batch_size=batch_size,\n","#                     validation_data=(x_test[0:batch_size*9], y_test_length[0:batch_size*9]), verbose=1)\n","length_history = length_model.fit(struct_x_train, y_train_length, epochs=40, validation_data=(struct_x_test, y_test_length), callbacks=[checkpoint], verbose=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8F52-F_y2Z3"},"source":["length_model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CefuSVtpsic"},"source":["# width_history = width_model.fit(x_train, y_train_width,\n","#                                 epochs=1, batch_size=batch_size,\n","#                                 validation_data=(x_test[0:batch_size*9], y_test_width[0:batch_size*9]), verbose=1)\n","width_history = width_model.fit(struct_x_train, y_train_width, epochs=40, validation_data=(struct_x_test, y_test_width), callbacks=[checkpoint], verbose=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZmxPdEj0KHG"},"source":["width_model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QthVS5Txp1-R"},"source":["# height_history = height_model.fit(x_train, y_train_height,\n","#                     epochs=5, batch_size=batch_size,\n","#                     validation_data=(x_test[0:batch_size*9], y_test_height[0:batch_size*9]), verbose=1)\n","height_history = height_model.fit(struct_x_train, y_train_height, epochs=40, validation_data=(struct_x_test, y_test_height), callbacks=[checkpoint], verbose=2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVZ0Ixxpcl7u"},"source":["height_model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g9DhCICTFnVJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrKBxPXGAJzW"},"source":["'''\n","Load the best model, this can only be used if you use GloVe embedding (TF2)\n","'''\n","model.load_weights(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"50grBDX96n8V"},"source":["pred = model.predict(x_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WX1V5HAQP9Sy"},"source":["idx_to_weight = {v: k for k, v in weight_to_idx.items()}\n","idx_to_volume = {v: k for k, v in volume_to_idx.items()}\n","idx_to_length = {v: k for k, v in length_to_idx.items()}\n","idx_to_width = {v: k for k, v in width_to_idx.items()}\n","idx_to_height = {v: k for k, v in height_to_idx.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7jYYVX0IkkJ"},"source":["# Prepare ground truth (from onehot back to actual measurement)\n","def get_numeric_true_metric(onehot, idx_dict):\n","  num_arr = []\n","  for i in onehot:\n","    num_arr.append(int(idx_dict[np.argmax(i)]))\n","  return num_arr\n","true_weight = get_numeric_true_metric(y_test_weight, idx_to_weight)\n","true_volume = get_numeric_true_metric(y_test_volume, idx_to_volume)\n","true_length = get_numeric_true_metric(y_test_length, idx_to_length)\n","true_width = get_numeric_true_metric(y_test_width, idx_to_width)\n","true_height = get_numeric_true_metric(y_test_height, idx_to_height)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQj5KwO_JuU4"},"source":["# Now look at the predicted values\n","# Material -> Colour -> Weight -> Volume -> Object -> Length -> Width -> Height\n","# Index of the property relating to the models\n","# prop_idx = [2, 3, 5, 6, 7]\n","'''\n","NOTE: this needs to be changed if the model is single output\n","for example\n","pred_weight, pred_weight_val = pred, []\n","pred_volume, pred_volume_val = pred, []\n","pred_length, pred_length_val = pred, []\n","pred_width, pred_width_val = pred, []\n","pred_height, pred_height_val = pred, []\n","'''\n","pred_weight, pred_weight_val = pred[2], []\n","pred_volume, pred_volume_val = pred[3], []\n","pred_length, pred_length_val = pred[5], []\n","pred_width, pred_width_val = pred[6], []\n","pred_height, pred_height_val = pred[7], []\n","\n","def convert_to_number(pred, val, idx_dict):\n","  for i in range(len(pred)):\n","    val.append(int(idx_dict[np.argmax(pred[i])]))\n","convert_to_number(pred_weight, pred_weight_val, idx_to_weight)\n","convert_to_number(pred_volume, pred_volume_val, idx_to_volume)\n","convert_to_number(pred_length, pred_length_val, idx_to_length)\n","convert_to_number(pred_width, pred_width_val, idx_to_width)\n","convert_to_number(pred_height, pred_height_val, idx_to_height)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JouKZ3oxEHb2"},"source":["def get_abs_error(true, pred):\n","  abs_arr = []\n","  for i in range(len(true)):\n","    abs_arr.append(abs(true[i] - pred[i]))\n","  return abs_arr\n","\n","weight_abs_error = np.asarray(get_abs_error(true_weight, pred_weight_val))\n","volume_abs_error = np.asarray(get_abs_error(true_volume, pred_volume_val))\n","length_abs_error = np.asarray(get_abs_error(true_length, pred_length_val))\n","width_abs_error = np.asarray(get_abs_error(true_width, pred_width_val))\n","height_abs_error = np.asarray(get_abs_error(true_height, pred_height_val))\n","print(f'Mean absolute error of weight: {np.mean(weight_abs_error)}g')\n","print(f'Mean absolute error of volume: {np.mean(volume_abs_error)}ml')\n","print(f'Mean absolute error of length: {np.mean(length_abs_error)}cm')\n","print(f'Mean absolute error of width : {np.mean(width_abs_error)}cm')\n","print(f'Mean absolute error of height: {np.mean(height_abs_error)}cm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"65kiOLF94UbH"},"source":["!mkdir experiment4_glove"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6edUCfFz20c8"},"source":["plt.style.use(\"ggplot\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXfyuRAF3gBK"},"source":["def plot_abs_error(abs_error, property):\n","  abs_error = abs_error[abs_error != 0]\n","  weights = np.ones_like(abs_error) / len(abs_error)\n","  fig = plt.figure(figsize=(10, 4), dpi=200)\n","  ax1 = fig.add_subplot(1, 1, 1)\n","  ax1.hist(abs_error, weights=weights, bins=200)\n","  ax1.set_xlabel('Absolute Error')\n","  ax1.set_ylabel('Normalized Frequency')\n","  ax1.set_title(f'Absolute error on {property} prediction')\n","  plt.savefig(f'./experiment4_glove/{property}.png')\n","\n","plot_abs_error(weight_abs_error, 'weight')\n","plot_abs_error(volume_abs_error, 'volume')\n","plot_abs_error(length_abs_error, 'length')\n","plot_abs_error(width_abs_error, 'width')\n","plot_abs_error(height_abs_error, 'height')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vID7T4786wK-"},"source":["!zip -r download6.zip ./experiment6_glove"],"execution_count":null,"outputs":[]}]}